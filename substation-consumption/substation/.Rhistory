PointType=-5
#Find all PointType in the PointRange
#2. Use data from these point back 1 year to train data
#3. Do prediction and evaluate performance
#return(IndexRange)
for (i in 1:10){
LastTrainingPoint=TimeSet(PointType,Npoints=30,PointRange)
cl <- makeCluster(3)
registerDoParallel(cl)
df=foreach(LastPoint=LastTrainingPoint,.packages=c('RCurl','xml2','digest','httr','tseries','forecast','imputeTS')) %dopar% train_predict(toString(SubstationIDs[i]),LastPoint,Nahead=168)
save('df',file=file.path(getwd(),paste0(toString(ss),'.RData')))
stopCluster(cl)}
source('C:/Users/Hoang Tran/Projects/substation/code_deploy/Lib/utilities.R', echo=TRUE)
train_predict(toString(SubstationIDs[1]),LastPoint,Nahead=168)
train_predict(toString(SubstationIDs[1]),LastPoint,Nahead=168)
train_predict(toString(SubstationIDs[1]),LastTrainingPoint[1],Nahead=168)
require(imputeTS)
train_predict(toString(SubstationIDs[1]),LastTrainingPoint[1],Nahead=168)
timeIDs[length(timeIDs)]
train_predict(toString(SubstationIDs[2]),LastTrainingPoint[1],Nahead=168)
require(imputeTS)
train_predict(toString(SubstationIDs[1]),LastTrainingPoint[1],Nahead=168)
timeIDs
timeIDs[length(timeIDs)]
require(imputeTS)
train_predict(toString(SubstationIDs[2]),LastTrainingPoint[1],Nahead=168)
require(imputeTS)
train_predict(toString(SubstationIDs[2]),LastTrainingPoint[1],Nahead=168)
ss
ss
require(imputeTS)
train_predict(toString(SubstationIDs[2]),LastTrainingPoint[1],Nahead=168)
timeIDs[length[timeIDs]]
timeIDs[length(timeIDs)]
y[length(y)]
timeIDs[length(timeIDs)-1]
timeIDs[length(timeIDs)-2]
timeIDs[length(timeIDs)-1]+3600
which(is.na(timeIDs))
naID=which(is.na(timeIDs))
timeIDs[naID]=timeIDs[naID-1]+3600
source('C:/Users/Hoang Tran/Projects/substation/code_deploy/Lib/utilities.R', echo=TRUE)
require(imputeTS)
train_predict(toString(SubstationIDs[2]),LastTrainingPoint[1],Nahead=168)
source('C:/Users/Hoang Tran/Projects/substation/code_deploy/Lib/utilities.R', echo=TRUE)
require(imputeTS)
train_predict(toString(SubstationIDs[2]),LastTrainingPoint[1],Nahead=168)
require(imputeTS)
require(forecast)
train_predict(toString(SubstationIDs[2]),LastTrainingPoint[1],Nahead=168)
Q
PathToMeterFile = file.path(getwd(),'Lib','substation_relations.csv')
meters=read.csv(PathToMeterFile,encoding='latin-1')
meters = meters[complete.cases(meters), ]
SubstationIDs = unique(meters$SubstationName)
require(doParallel)
PointRange=c("2017-01-01T00:01:00Z","2017-09-01T00:01:00Z")
PointType=-5
#Find all PointType in the PointRange
#2. Use data from these point back 1 year to train data
#3. Do prediction and evaluate performance
#return(IndexRange)
for (i in 1:10){
print(i)
LastTrainingPoint=TimeSet(PointType,Npoints=30,PointRange)
cl <- makeCluster(3)
registerDoParallel(cl)
df=foreach(LastPoint=LastTrainingPoint,.packages=c('RCurl','xml2','digest','httr','tseries','forecast','imputeTS')) %dopar% train_predict(toString(SubstationIDs[i]),LastPoint,Nahead=168)
save('df',file=file.path(getwd(),paste0(toString(ss),'.RData')))
stopCluster(cl)}
source('C:/Users/Hoang Tran/Projects/substation/code_deploy/Lib/utilities.R', echo=TRUE)
PathToMeterFile = file.path(getwd(),'Lib','substation_relations.csv')
meters=read.csv(PathToMeterFile,encoding='latin-1')
meters = meters[complete.cases(meters), ]
SubstationIDs = unique(meters$SubstationName)
require(doParallel)
PointRange=c("2017-01-01T00:01:00Z","2017-09-01T00:01:00Z")
PointType=-5
#Find all PointType in the PointRange
#2. Use data from these point back 1 year to train data
#3. Do prediction and evaluate performance
#return(IndexRange)
for (i in 1:10){
print(i)
LastTrainingPoint=TimeSet(PointType,Npoints=30,PointRange)
cl <- makeCluster(3)
registerDoParallel(cl)
df=foreach(LastPoint=LastTrainingPoint,.packages=c('RCurl','xml2','digest','httr','tseries','forecast','imputeTS')) %dopar% train_predict(toString(SubstationIDs[i]),LastPoint,Nahead=168)
save('df',file=file.path(getwd(),paste0(toString(ss),'.RData')))
stopCluster(cl)}
SubstationIDs = unique(meters$SubstationName)
lenSub=SubstationIDs
for (i in 1:length(SubstationIDs)){
lenSub[i]=which(meters$SubstationName==toString(SubstationIDs[i]))
}
lenSub=0
for (i in 1:length(SubstationIDs)){
lenSub=append(lenSub,length(which(meters$SubstationName==toString(SubstationIDs[i]))))
}
lenSub
sort(lenSub)
source('C:/Users/Hoang Tran/Projects/substation/code_deploy/Lib/utilities.R', echo=TRUE)
PathToMeterFile = file.path(getwd(),'Lib','substation_relations.csv')
meters=read.csv(PathToMeterFile,encoding='latin-1')
meters = meters[complete.cases(meters), ]
SubstationIDs = unique(meters$SubstationName)
lenSub=0
for (i in 1:length(SubstationIDs)){
lenSub=append(lenSub,length(which(meters$SubstationName==toString(SubstationIDs[i]))))
}
lenorder=order(lenSub,decreasing = TRUE)
require(doParallel)
PointRange=c("2017-01-01T00:01:00Z","2017-09-01T00:01:00Z")
PointType=-5
#Find all PointType in the PointRange
#2. Use data from these point back 1 year to train data
#3. Do prediction and evaluate performance
#return(IndexRange)
for (id in 2:10){
i=lenorder[id]-1
print(i)
LastTrainingPoint=TimeSet(PointType,Npoints=30,PointRange)
cl <- makeCluster(3)
registerDoParallel(cl)
df=foreach(LastPoint=LastTrainingPoint,.packages=c('RCurl','xml2','digest','httr','tseries','forecast','imputeTS')) %dopar% train_predict(toString(SubstationIDs[i]),LastPoint,Nahead=168)
save('df',file=file.path(getwd(),paste0(toString(ss),'.RData')))
stopCluster(cl)}
PathToMeterFile = file.path(getwd(),'Lib','substation_relations.csv')
meters=read.csv(PathToMeterFile,encoding='latin-1')
meters = meters[complete.cases(meters), ]
SubstationIDs = unique(meters$SubstationName)
lenSub=0
for (i in 1:length(SubstationIDs)){
lenSub=append(lenSub,length(which(meters$SubstationName==toString(SubstationIDs[i]))))
}
lenorder=order(lenSub,decreasing = TRUE)
require(doParallel)
PointRange=c("2017-01-01T00:01:00Z","2017-09-01T00:01:00Z")
PointType=-5
#Find all PointType in the PointRange
#2. Use data from these point back 1 year to train data
#3. Do prediction and evaluate performance
#return(IndexRange)
for (id in 1:10){
i=lenorder[id]-1
print(i)
LastTrainingPoint=TimeSet(PointType,Npoints=3,PointRange)
cl <- makeCluster(3)
registerDoParallel(cl)
df=foreach(LastPoint=LastTrainingPoint,.packages=c('RCurl','xml2','digest','httr','tseries','forecast','imputeTS')) %dopar% train_predict(toString(SubstationIDs[i]),LastPoint,Nahead=168)
save('df',file=file.path(getwd(),paste0(toString(ss),'.RData')))
stopCluster(cl)}
PathToMeterFile = file.path(getwd(),'Lib','substation_relations.csv')
meters=read.csv(PathToMeterFile,encoding='latin-1')
meters = meters[complete.cases(meters), ]
SubstationIDs = unique(meters$SubstationName)
lenSub=0
for (i in 1:length(SubstationIDs)){
lenSub=append(lenSub,length(which(meters$SubstationName==toString(SubstationIDs[i]))))
}
lenorder=order(lenSub,decreasing = TRUE)
require(doParallel)
PointRange=c("2017-01-01T00:01:00Z","2017-09-01T00:01:00Z")
PointType=-5
#Find all PointType in the PointRange
#2. Use data from these point back 1 year to train data
#3. Do prediction and evaluate performance
#return(IndexRange)
for (id in 1:20){
i=lenorder[id]-1
print(i)
LastTrainingPoint=TimeSet(PointType,Npoints=30,PointRange)
cl <- makeCluster(3)
registerDoParallel(cl)
df=foreach(LastPoint=LastTrainingPoint,.packages=c('RCurl','xml2','digest','httr','tseries','forecast','imputeTS')) %dopar% train_predict(toString(SubstationIDs[i]),LastPoint,Nahead=168)
save('df',file=file.path(getwd(),paste0(toString(SubstationIDs[i]),'.RData')))
stopCluster(cl)}
PathToMeterFile = file.path(getwd(),'Lib','substation_relations.csv')
meters=read.csv(PathToMeterFile,encoding='latin-1')
meters = meters[complete.cases(meters), ]
SubstationIDs = unique(meters$SubstationName)
lenSub=0
for (i in 1:length(SubstationIDs)){
lenSub=append(lenSub,length(which(meters$SubstationName==toString(SubstationIDs[i]))))
}
lenorder=order(lenSub,decreasing = TRUE)
require(doParallel)
PointRange=c("2017-01-01T00:01:00Z","2017-09-01T00:01:00Z")
PointType=-1
#Find all PointType in the PointRange
#2. Use data from these point back 1 year to train data
#3. Do prediction and evaluate performance
#return(IndexRange)
for (id in 1:20){
i=lenorder[id]-1
print(i)
LastTrainingPoint=TimeSet(PointType,Npoints=3,PointRange)
cl <- makeCluster(3)
registerDoParallel(cl)
df=foreach(LastPoint=LastTrainingPoint,.packages=c('RCurl','xml2','digest','httr','tseries','forecast','imputeTS')) %dopar% data.frame(train_predict(toString(SubstationIDs[i]),LastPoint,Nahead=168))
save('df',file=file.path(getwd(),paste0(toString(SubstationIDs[i]),toString(PointType),'.RData')))
stopCluster(cl)}
PathToMeterFile = file.path(getwd(),'Lib','substation_relations.csv')
meters=read.csv(PathToMeterFile,encoding='latin-1')
meters = meters[complete.cases(meters), ]
SubstationIDs = unique(meters$SubstationName)
lenSub=0
for (i in 1:length(SubstationIDs)){
lenSub=append(lenSub,length(which(meters$SubstationName==toString(SubstationIDs[i]))))
}
lenorder=order(lenSub,decreasing = TRUE)
require(doParallel)
PointRange=c("2017-01-01T00:01:00Z","2017-09-01T00:01:00Z")
PointType=-1
#Find all PointType in the PointRange
#2. Use data from these point back 1 year to train data
#3. Do prediction and evaluate performance
#return(IndexRange)
for (id in 1:20){
i=lenorder[id]-1
print(i)
LastTrainingPoint=TimeSet(PointType,Npoints=30,PointRange)
cl <- makeCluster(3)
registerDoParallel(cl)
df=foreach(LastPoint=LastTrainingPoint,.packages=c('RCurl','xml2','digest','httr','tseries','forecast','imputeTS')) %dopar% train_predict(toString(SubstationIDs[i]),LastPoint,Nahead=168)
save('df',file=file.path(getwd(),paste0(toString(SubstationIDs[i]),toString(PointType),'.RData')))
stopCluster(cl)}
PathToMeterFile = file.path(getwd(),'Lib','substation_relations.csv')
meters=read.csv(PathToMeterFile,encoding='latin-1')
meters = meters[complete.cases(meters), ]
SubstationIDs = unique(meters$SubstationName)
lenSub=0
for (i in 1:length(SubstationIDs)){
lenSub=append(lenSub,length(which(meters$SubstationName==toString(SubstationIDs[i]))))
}
lenorder=order(lenSub,decreasing = TRUE)
require(doParallel)
PointRange=c("2017-01-01T00:01:00Z","2017-09-01T00:01:00Z")
PointType=-1#previously -5
#Find all PointType in the PointRange
#2. Use data from these point back 1 year to train data
#3. Do prediction and evaluate performance
#return(IndexRange)
for (id in 3:20){
i=lenorder[id]-1
print(i)
LastTrainingPoint=TimeSet(PointType,Npoints=30,PointRange)
cl <- makeCluster(3)
registerDoParallel(cl)
df=foreach(LastPoint=LastTrainingPoint,.packages=c('RCurl','xml2','digest','httr','tseries','forecast','imputeTS')) %dopar% train_predict(toString(SubstationIDs[i]),LastPoint,Nahead=168)
save('df',file=file.path(getwd(),paste0(toString(SubstationIDs[i]),toString(PointType),'.RData')))
stopCluster(cl)}
knitr::opts_chunk$set(echo = TRUE)
print('This is the set up chunk')
for (n in x) print(n)
x
for (n in x) print(n)
x <- c(1,2,4)
for (n in x) print(n)
seq(from=12,to=30,by=3)
x=seq(from=12,to=30,by=3)
for (i in seq(x))
print(i)
x <- 1:8
z12 <- function(z) return(c(z,z^2))
sapply(1:8,z12)
z <- NULL
for (i in 1:10) if (i %%2 == 0) z<-c(z,i)
z
z <- NULL
for (i in 1:10) if (i %%2 == 0) z<-maxtrix(z,rep(i,3))
z <- NULL
for (i in 1:10) if (i %%2 == 0) z<-matrix(z,rep(i,3))
z <- NULL
for (i in 1:10) if (i %%2 == 0) z<-c(z,rep(i,3))
z
z <- NULL
for (i in 1:10) if (i %%2 == 0) z<-c(z,i)
z
z <- c(5,2,-3,8)
y <- c(1,2,30,5)
y[z*z>8]
x <- c(5,2,9,12)
ifelse(x %% 2==0,0,1)
PeformanceEvaluation <- function(ss,Npoints,PointType,PointRange,Method){
####This function will evaluate the performance of a Method (method) at different type of time (PointType): weekend, weekday, night, general, each hour when applying to a substation ss
#Randomly generate Npoints of PointType in the PointRange. PointRange[1]: starting hour,     PointRange[2]: Last hour, format: "Y-m-dTH:M:SZ"
LastTrainingPoint=TimeSet(PointType,Npoints=3,PointRange)
cl <- makeCluster(3)
registerDoParallel(cl)
df=foreach(LastPoint=LastTrainingPoint,.packages=c('RCurl','xml2','digest','httr','tseries','forecast','imputeTS')) %dopar% train_predict('570HT1',LastPoint,168)
stopCluster(cl)
save('df',file=paste(ss,'.RData'))
}
TimeSet<-function(PointType,Npoints=30,PointRange=c('2017-01-01T00:01:00Z','2017-09-01T00:01:00Z')){
#type = -2 for weekend, -1 for weekday, -3 for night time(6pm to 6am),-4 for day time(6am to 6pm) h for hour h of the day, -5 for general performance, a vector for a certain set of time
#This function will generate all hours of certain type in a range of time
PointRangeStart=as.POSIXct(PointRange[1],format="%Y-%m-%d T %H:%M:%S Z", tz="UTC")
PointRangeEnd=as.POSIXct(PointRange[2],format="%Y-%m-%d T %H:%M:%S Z", tz="UTC")
IndexRange=as.numeric(difftime(PointRangeEnd,PointRangeStart,units='hour'))
AllTimeSet=PointRangeStart+3600*c(1:IndexRange)
if (PointType==-1){#weekday
HourSet=AllTimeSet[which(weekdays(AllTimeSet)%in%c('Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday'))]
}
if (PointType==-2){#weekend
HourSet=AllTimeSet[which(weekdays(AllTimeSet)%in%c('Saturday', 'Sunday'))]
}
if (PointType==-3){#night time
HourSet=AllTimeSet[which(as.numeric(format(as.POSIXct(AllTimeSet,format="%H:%M:%S"),"%H"))%in%c(18:23,0:6))]
}
if (PointType==-4){#day time
HourSet=AllTimeSet[which(as.numeric(format(as.POSIXct(AllTimeSet,format="%H:%M:%S"),"%H"))%in%c(6:18))]
}
if (PointType==-5){#general hour
HourSet=AllTimeSet
}
if (PointType>=0){#each hour
HourSet=AllTimeSet[which(as.numeric(format(as.POSIXct(AllTimeSet,format="%H:%M:%S"),"%H"))%in%c(PointType))]
}
if (length(PointType)>1){#certain set of time in the day
HourSet=AllTimeSet[which(as.numeric(format(as.POSIXct(AllTimeSet,format="%H:%M:%S"),"%H"))%in%PointType)]
}
IndexToSample=sample(1:length(HourSet), Npoints, replace=F)
HourSet=HourSet[IndexToSample]
return(HourSet)
}
train_predict <-function(ss,LastPoint,Ndays=365,Nahead){
#ss='570HT1'
#LastPoint=LastTrainingPoint[1]
#Ndays=365
#Nahead=72
HMS=format(as.POSIXct(LastPoint,format="%H:%M:%S"),"%H:%M:%S")
lastday=format(as.POSIXct(LastPoint+Nahead*3600,format="%Y-%m-%d"),"%Y-%m-%d")
firstday=format(as.POSIXct(LastPoint-Ndays*24*3600,format="%Y-%m-%d"),"%Y-%m-%d")
FirstTimePoint=paste0(firstday,'T',toString(HMS),'Z')
HMS=format(as.POSIXct(LastPoint+Nahead*3600,format="%H:%M:%S"),"%H:%M:%S")
LastTimePoint=paste0(lastday,'T',toString(HMS),'Z')
y=utilities.download_data_from_url(ss,FirstTimePoint,LastTimePoint)
ytrain=y[1:(length(y)-Nahead)]
ytest=y[(length(y)-Nahead+1):length(y)]
dshw_model=dshw(ytrain,period1=24,period2=24*7)
dshw_model1=dshw(y=ytrain,h= Nahead, model=dshw_model)
y_hat<-c(dshw_model1$mean)
return(c(y_hat,ytest))
}
#tem=train_predict('570HT1',LastTrainingPoint[1],365,72)
PathToMeterFile = file.path(getwd(),'Lib','substation_relations.csv')
meters=read.csv(PathToMeterFile,encoding='latin-1')
meters = meters[complete.cases(meters), ]
SubstationIDs = unique(meters$SubstationName)
lenSub=0
for (i in 1:length(SubstationIDs)){
lenSub=append(lenSub,length(which(meters$SubstationName==toString(SubstationIDs[i]))))
}
lenorder=order(lenSub,decreasing = TRUE)
require(doParallel)
PointRange=c("2017-01-01T00:01:00Z","2017-09-01T00:01:00Z")
PointType=-1#previously -5
#Find all PointType in the PointRange
#2. Use data from these point back 1 year to train data
#3. Do prediction and evaluate performance
#return(IndexRange)
for (id in 3:20){
i=lenorder[id]-1
print(i)
LastTrainingPoint=TimeSet(PointType,Npoints=30,PointRange)
cl <- makeCluster(3)
registerDoParallel(cl)
df=foreach(LastPoint=LastTrainingPoint,.packages=c('RCurl','xml2','digest','httr','tseries','forecast','imputeTS')) %dopar% train_predict(toString(SubstationIDs[i]),LastPoint,Nahead=168)
save('df',file=file.path(getwd(),paste0(toString(SubstationIDs[i]),toString(PointType),'.RData')))
stopCluster(cl)}
install.packages('forecast')
PathToMeterFile = file.path(getwd(),'Lib','substation_relations.csv')
meters=read.csv(PathToMeterFile,encoding='latin-1')
meters = meters[complete.cases(meters), ]
SubstationIDs = unique(meters$SubstationName)
lenSub=0
for (i in 1:length(SubstationIDs)){
lenSub=append(lenSub,length(which(meters$SubstationName==toString(SubstationIDs[i]))))
}
lenorder=order(lenSub,decreasing = TRUE)
require(doParallel)
PointRange=c("2017-01-01T00:01:00Z","2017-09-01T00:01:00Z")
PointType=-1#previously -5
#Find all PointType in the PointRange
#2. Use data from these point back 1 year to train data
#3. Do prediction and evaluate performance
#return(IndexRange)
for (id in 3:20){
i=lenorder[id]-1
print(i)
LastTrainingPoint=TimeSet(PointType,Npoints=30,PointRange)
cl <- makeCluster(3)
registerDoParallel(cl)
df=foreach(LastPoint=LastTrainingPoint,.packages=c('RCurl','xml2','digest','httr','tseries','forecast','imputeTS')) %dopar% train_predict(toString(SubstationIDs[i]),LastPoint,Nahead=168)
save('df',file=file.path(getwd(),paste0(toString(SubstationIDs[i]),toString(PointType),'.RData')))
stopCluster(cl)}
setwd('C:/Users/Hoang Tran/Projects/substation/code_deploy')
source(file.path(getwd(), 'Lib','utilities.R'))
PathToMeterFile = file.path(getwd(),'Lib','substation_relations.csv')
meters=read.csv(PathToMeterFile,encoding='latin-1')
meters = meters[complete.cases(meters), ]
SubstationIDs = unique(meters$SubstationName)
lenSub=0
for (i in 1:length(SubstationIDs)){
lenSub=append(lenSub,length(which(meters$SubstationName==toString(SubstationIDs[i]))))
}
lenorder=order(lenSub,decreasing = TRUE)
require(doParallel)
PointRange=c("2017-01-01T00:01:00Z","2017-09-01T00:01:00Z")
PointType=-1#previously -5
#Find all PointType in the PointRange
#2. Use data from these point back 1 year to train data
#3. Do prediction and evaluate performance
#return(IndexRange)
for (id in 3:20){
i=lenorder[id]-1
print(i)
LastTrainingPoint=TimeSet(PointType,Npoints=30,PointRange)
cl <- makeCluster(3)
registerDoParallel(cl)
df=foreach(LastPoint=LastTrainingPoint,.packages=c('RCurl','xml2','digest','httr','tseries','forecast','imputeTS')) %dopar% train_predict(toString(SubstationIDs[i]),LastPoint,Nahead=168)
save('df',file=file.path(getwd(),paste0(toString(SubstationIDs[i]),toString(PointType),'.RData')))
stopCluster(cl)}
PathToMeterFile = file.path(getwd(),'Lib','substation_relations.csv')
meters=read.csv(PathToMeterFile,encoding='latin-1')
meters = meters[complete.cases(meters), ]
SubstationIDs = unique(meters$SubstationName)
lenSub=0
for (i in 1:length(SubstationIDs)){
lenSub=append(lenSub,length(which(meters$SubstationName==toString(SubstationIDs[i]))))
}
lenorder=order(lenSub,decreasing = TRUE)
require(doParallel)
PointRange=c("2017-01-01T00:01:00Z","2017-09-01T00:01:00Z")
PointType=-1#previously -5
#Find all PointType in the PointRange
#2. Use data from these point back 1 year to train data
#3. Do prediction and evaluate performance
#return(IndexRange)
for (id in 9:20){
i=lenorder[id]-1
print(i)
LastTrainingPoint=TimeSet(PointType,Npoints=30,PointRange)
cl <- makeCluster(3)
registerDoParallel(cl)
df=foreach(LastPoint=LastTrainingPoint,.packages=c('RCurl','xml2','digest','httr','tseries','forecast','imputeTS')) %dopar% train_predict(toString(SubstationIDs[i]),LastPoint,Nahead=168)
save('df',file=file.path(getwd(),paste0(toString(SubstationIDs[i]),toString(PointType),'.RData')))
stopCluster(cl)}
PathToMeterFile = file.path(getwd(),'Lib','substation_relations.csv')
meters=read.csv(PathToMeterFile,encoding='latin-1')
meters = meters[complete.cases(meters), ]
SubstationIDs = unique(meters$SubstationName)
lenSub=0
for (i in 1:length(SubstationIDs)){
lenSub=append(lenSub,length(which(meters$SubstationName==toString(SubstationIDs[i]))))
}
lenorder=order(lenSub,decreasing = TRUE)
require(doParallel)
PointRange=c("2017-01-01T00:01:00Z","2017-09-01T00:01:00Z")
PointType=-1#previously -5
#Find all PointType in the PointRange
#2. Use data from these point back 1 year to train data
#3. Do prediction and evaluate performance
#return(IndexRange)
for (id in 9:20){
i=lenorder[id]-1
print(i)
LastTrainingPoint=TimeSet(PointType,Npoints=30,PointRange)
cl <- makeCluster(3)
registerDoParallel(cl)
df=foreach(LastPoint=LastTrainingPoint,.packages=c('RCurl','xml2','digest','httr','tseries','forecast','imputeTS')) %dopar% train_predict(toString(SubstationIDs[i]),LastPoint,Nahead=168)
save('df',file=file.path(getwd(),paste0(toString(SubstationIDs[i]),toString(PointType),'.RData')))
stopCluster(cl)}
lenorder[9]
lenorder[8'']
lenorder[8]
PathToMeterFile = file.path(getwd(),'Lib','substation_relations.csv')
meters=read.csv(PathToMeterFile,encoding='latin-1')
meters = meters[complete.cases(meters), ]
SubstationIDs = unique(meters$SubstationName)
lenSub=0
for (i in 1:length(SubstationIDs)){
lenSub=append(lenSub,length(which(meters$SubstationName==toString(SubstationIDs[i]))))
}
lenorder=order(lenSub,decreasing = TRUE)
require(doParallel)
PointRange=c("2017-01-01T00:01:00Z","2017-09-01T00:01:00Z")
PointType=-1#previously -5
#Find all PointType in the PointRange
#2. Use data from these point back 1 year to train data
#3. Do prediction and evaluate performance
#return(IndexRange)
for (id in 9:20){
i=lenorder[id]-1
print(i)
LastTrainingPoint=TimeSet(PointType,Npoints=30,PointRange)
cl <- makeCluster(3)
registerDoParallel(cl)
df=foreach(LastPoint=LastTrainingPoint,.packages=c('RCurl','xml2','digest','httr','tseries','forecast','imputeTS')) %dopar% train_predict(toString(SubstationIDs[i]),LastPoint,Nahead=168)
save('df',file=file.path(getwd(),paste0(toString(SubstationIDs[i]),toString(PointType),'.RData')))
stopCluster(cl)}
setwd("C:/Users/Hoang Tran/Projects/substation/substation-web-services-uploaded-to-dockerv2/substation-consumption/substation")
require(xts)
source(file.path(getwd(), 'Lib','dshw_functions.R'))
source(file.path(getwd(), 'Lib','GamModels.R'))
source(file.path(getwd(), 'Lib','Utilities.R'))
source(file.path(getwd(), 'Lib','azure_blob_call.R'))
load(file.path(getwd(), 'Lib','Overloaded.RData'))
PathToMeterFile = file.path(getwd(),'Lib','substation_relations.csv')
SubstationMeterRelation=read.csv(PathToMeterFile,encoding='latin-1')
SubstationMeterRelation=data.frame(SubstationId=SubstationMeterRelation$SubstationId,MeterId=SubstationMeterRelation$MeterId)
